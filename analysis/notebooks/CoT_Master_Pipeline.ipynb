{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üß† O-ISAC CoT Master Pipeline\n",
                "\n",
                "Tek notebook ile t√ºm extraction pipeline'ƒ± √ßalƒ±≈ütƒ±r.\n",
                "\n",
                "**A≈üamalar:**\n",
                "1. üì¶ Setup & Mount\n",
                "2. üè≠ Phase 1: Data Prep (PDF ‚Üí Markdown)\n",
                "3. üñºÔ∏è Phase 2: Visual Analysis\n",
                "4. üß† Phase 3: CoT Extraction\n",
                "5. üìä Results & Export\n",
                "\n",
                "**Gereksinimler:**\n",
                "- Colab GPU Runtime (T4 veya A100)\n",
                "- GROQ_API_KEY (Colab Secrets'da ayarlƒ±)\n",
                "\n",
                "---\n",
                "**Son G√ºncelleme:** 2025-12-11\n",
                "**Versiyon:** 1.0"
            ],
            "metadata": {
                "id": "header_main"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## üì¶ Section 1: Setup & Mount"
            ],
            "metadata": {
                "id": "section_1_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 1.1 Install Dependencies\n",
                "# Phase 1 & 2 heavy dependencies\n",
                "!pip install marker-pdf -q\n",
                "!pip install transformers torch pillow -q\n",
                "\n",
                "# Phase 3 light dependencies\n",
                "!pip install groq nest_asyncio pandas pyyaml -q\n",
                "\n",
                "print(\"‚úÖ T√ºm baƒüƒ±mlƒ±lƒ±klar y√ºklendi!\")"
            ],
            "metadata": {
                "id": "install_deps"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 1.2 Mount Google Drive & Setup Paths\n",
                "from google.colab import drive\n",
                "from google.colab import userdata\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Mount Drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Project Paths\n",
                "PROJECT_ROOT = '/content/drive/MyDrive/AKU_WorkSpace/survey_fdgit/OISAC_PRISMA_COMST'\n",
                "NOTEBOOKS_DIR = os.path.join(PROJECT_ROOT, 'analysis/notebooks')\n",
                "COT_LAB_DIR = os.path.join(PROJECT_ROOT, 'analysis/cot_laboratory')\n",
                "PDF_DIR = os.path.join(PROJECT_ROOT, 'data/retrieved_docs')\n",
                "MARKDOWN_DIR = os.path.join(PROJECT_ROOT, 'data/processed_markdowns')\n",
                "OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'data/extraction_results_v3')\n",
                "\n",
                "# Add to Python Path\n",
                "sys.path.insert(0, NOTEBOOKS_DIR)\n",
                "sys.path.insert(0, PROJECT_ROOT)\n",
                "\n",
                "print(f\"üìÅ Project Root: {PROJECT_ROOT}\")\n",
                "print(f\"üìÑ PDF Directory: {PDF_DIR}\")\n",
                "print(f\"üìù Markdown Directory: {MARKDOWN_DIR}\")\n",
                "print(f\"üìä Output Directory: {OUTPUT_DIR}\")\n",
                "print(\"‚úÖ Paths configured!\")"
            ],
            "metadata": {
                "id": "mount_drive"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 1.3 Load API Key\n",
                "try:\n",
                "    os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
                "    print(\"‚úÖ GROQ_API_KEY y√ºklendi!\")\n",
                "except Exception as e:\n",
                "    print(\"‚ùå HATA: Sol men√ºden üîë Secrets b√∂l√ºm√ºne GROQ_API_KEY ekleyin!\")\n",
                "    print(f\"   Hata detayƒ±: {e}\")"
            ],
            "metadata": {
                "id": "load_api_key"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## üè≠ Section 2: Phase 1 - Data Prep (PDF ‚Üí Markdown)\n",
                "\n",
                "**‚ö†Ô∏è GPU Gerektirir!** Bu adƒ±m PDF'leri OCR ile markdown'a √ßevirir."
            ],
            "metadata": {
                "id": "section_2_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 2.1 Import Pipeline & Check Status\n",
                "from extraction_pipeline_v3 import Config, CheckpointManager, phase1_marker_conversion\n",
                "\n",
                "# Initialize\n",
                "Config.init_dirs()\n",
                "checkpoint = CheckpointManager(Config.CHECKPOINT_FILE)\n",
                "\n",
                "# Show current status\n",
                "processed = checkpoint.data.get('processed', {})\n",
                "print(f\"üìä Mevcut durum: {len(processed)} paper i≈ülenmi≈ü\")\n",
                "print(f\"üìÇ PDF'ler: {PDF_DIR}\")\n",
                "\n",
                "# List PDFs\n",
                "import glob\n",
                "pdfs = glob.glob(os.path.join(PDF_DIR, '*.pdf'))\n",
                "print(f\"üìÑ Toplam PDF: {len(pdfs)}\")"
            ],
            "metadata": {
                "id": "check_status"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 2.2 Run PDF ‚Üí Markdown Conversion (Phase 1)\n",
                "# ‚ö†Ô∏è Bu adƒ±m uzun s√ºrebilir (paper ba≈üƒ±na ~1-2 dk)\n",
                "\n",
                "print(\"‚è≥ Phase 1: PDF ‚Üí Markdown d√∂n√º≈ü√ºm√º ba≈ülƒ±yor...\")\n",
                "phase1_marker_conversion(checkpoint, force_all=False)\n",
                "print(\"‚úÖ Phase 1 tamamlandƒ±!\")"
            ],
            "metadata": {
                "id": "run_phase1"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## üñºÔ∏è Section 3: Phase 2 - Visual Analysis\n",
                "\n",
                "BLIP ve DePlot modelleri ile g√∂rsel analiz yapƒ±lƒ±r."
            ],
            "metadata": {
                "id": "section_3_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 3.1 Run Visual Analysis (Phase 2)\n",
                "from extraction_pipeline_v3 import phase2_visual_analysis\n",
                "\n",
                "print(\"‚è≥ Phase 2: G√∂rsel analiz ba≈ülƒ±yor...\")\n",
                "phase2_visual_analysis(checkpoint)\n",
                "print(\"‚úÖ Phase 2 tamamlandƒ±!\")"
            ],
            "metadata": {
                "id": "run_phase2"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## üß† Section 4: Phase 3 - CoT Extraction\n",
                "\n",
                "Chain-of-Thought extraction ile yapƒ±sal veri √ßƒ±karma."
            ],
            "metadata": {
                "id": "section_4_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 4.1 Import CoT Laboratory\n",
                "sys.path.insert(0, COT_LAB_DIR)\n",
                "from core.assembler import CoTAssembler\n",
                "from core.batch_runner import CoTFactory\n",
                "\n",
                "# Default Recipe\n",
                "RECIPE_PATH = 'analysis/cot_laboratory/recipes/experiment_v1_full_analysis.yaml'\n",
                "\n",
                "print(\"‚úÖ CoT Laboratory y√ºklendi!\")\n",
                "print(f\"üìú Recipe: {RECIPE_PATH}\")"
            ],
            "metadata": {
                "id": "import_cot"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 4.2 Single Paper Test\n",
                "# √ñnce tek bir paper √ºzerinde test et\n",
                "\n",
                "TEST_PAPER_ID = \"O_ISAC_029\"  # @param {type:\"string\"}\n",
                "\n",
                "import json\n",
                "\n",
                "# Find paper markdown\n",
                "paper_path = os.path.join(MARKDOWN_DIR, TEST_PAPER_ID, TEST_PAPER_ID, f\"{TEST_PAPER_ID}.md\")\n",
                "vis_path = os.path.join(MARKDOWN_DIR, TEST_PAPER_ID, TEST_PAPER_ID, \"visual_analysis.txt\")\n",
                "\n",
                "print(f\"üìÑ Paper: {paper_path}\")\n",
                "print(f\"   Exists: {os.path.exists(paper_path)}\")\n",
                "\n",
                "# Read content\n",
                "with open(paper_path, 'r', encoding='utf-8') as f:\n",
                "    content = f.read()\n",
                "\n",
                "# Read visual if exists\n",
                "visual_content = None\n",
                "if os.path.exists(vis_path):\n",
                "    with open(vis_path, 'r', encoding='utf-8') as f:\n",
                "        visual_content = f.read()\n",
                "    print(f\"üñºÔ∏è Visual Analysis: {len(visual_content)} chars\")\n",
                "\n",
                "# Run extraction\n",
                "assembler = CoTAssembler(PROJECT_ROOT)\n",
                "result = assembler.run_extraction(\n",
                "    RECIPE_PATH,\n",
                "    content,\n",
                "    paper_id=TEST_PAPER_ID,\n",
                "    visual_content=visual_content\n",
                ")\n",
                "\n",
                "# Show result\n",
                "if result['status'] == 'success':\n",
                "    print(\"\\n‚úÖ EXTRACTION BA≈ûARILI!\")\n",
                "    print(\"\\nüìã Reasoning Trace:\")\n",
                "    trace = result['parsed_output'].get('reasoning_trace', [])\n",
                "    for step in trace:\n",
                "        print(f\"  {step.get('key')}: {step.get('value')[:80]}...\")\n",
                "else:\n",
                "    print(f\"\\n‚ùå HATA: {result.get('error_message')}\")"
            ],
            "metadata": {
                "id": "single_test"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 4.3 Batch Extraction (T√ºm Paper'lar)\n",
                "# ‚ö†Ô∏è Bu uzun s√ºrecek! ~2-3 dk per paper\n",
                "\n",
                "RUN_BATCH = False  # @param {type:\"boolean\"}\n",
                "\n",
                "if RUN_BATCH:\n",
                "    factory = CoTFactory(PROJECT_ROOT)\n",
                "    factory.run_batch(RECIPE_PATH)\n",
                "else:\n",
                "    print(\"‚ÑπÔ∏è Batch mode kapalƒ±. √áalƒ±≈ütƒ±rmak i√ßin RUN_BATCH = True yapƒ±n.\")"
            ],
            "metadata": {
                "id": "batch_extraction"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## üìä Section 5: Results & Export"
            ],
            "metadata": {
                "id": "section_5_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 5.1 View Latest Logs\n",
                "import glob\n",
                "\n",
                "logs_dir = os.path.join(COT_LAB_DIR, 'logs')\n",
                "log_files = sorted(glob.glob(os.path.join(logs_dir, '*_RESULT.json')))[-5:]\n",
                "\n",
                "print(f\"üìã Son 5 extraction log:\")\n",
                "for log in log_files:\n",
                "    filename = os.path.basename(log)\n",
                "    # Parse: 20251210_144637_O_ISAC_029_llama-3.3-70b-versatile_RESULT.json\n",
                "    parts = filename.split('_')\n",
                "    date = parts[0]\n",
                "    paper_id = f\"{parts[2]}_{parts[3]}_{parts[4]}\"\n",
                "    print(f\"  ‚Ä¢ {date}: {paper_id}\")"
            ],
            "metadata": {
                "id": "view_logs"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 5.2 Export to CSV (TODO)\n",
                "# Bu fonksiyon t√ºm log JSON'larƒ±nƒ± birle≈ütirip CSV'ye √ßevirecek\n",
                "\n",
                "print(\"üìä CSV export fonksiyonu hen√ºz implemente edilmedi.\")\n",
                "print(\"   Sonu√ßlar logs/ klas√∂r√ºnde JSON olarak mevcut.\")"
            ],
            "metadata": {
                "id": "export_csv"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## ‚úÖ Done!\n",
                "\n",
                "**Sonraki Adƒ±mlar:**\n",
                "1. Single paper test sonu√ßlarƒ±nƒ± kontrol et\n",
                "2. Kalite iyi ise batch mode'u a√ß\n",
                "3. T√ºm paper'larƒ± i≈üle\n",
                "4. CSV export yap"
            ],
            "metadata": {
                "id": "footer"
            }
        }
    ]
}